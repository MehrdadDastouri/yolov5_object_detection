{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWZBflKbFboKe1O+2m6dJp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehrdadDastouri/yolov5_object_detection/blob/main/yolov5_object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install YOLOv5 dependencies (if not installed)\n",
        "# !pip install torch torchvision matplotlib opencv-python ultralytics\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the YOLOv5 model (pre-trained on COCO dataset)\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # You can use 'yolov5m', 'yolov5l', 'yolov5x' for larger models\n",
        "\n",
        "# Load an image\n",
        "image_path = \"sample_image.jpg\"  # Replace with the path to your image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Perform object detection\n",
        "results = model(image)\n",
        "\n",
        "# Show results\n",
        "results.print()  # Print detected objects and their confidence scores\n",
        "results.show()   # Display the image with bounding boxes\n",
        "results.save()   # Save the image with bounding boxes to 'runs/detect/'\n",
        "\n",
        "# Extract detection details\n",
        "detections = results.pandas().xyxy[0]  # Bounding boxes and predictions\n",
        "print(detections)\n",
        "\n",
        "# Visualize the results using OpenCV\n",
        "def visualize_results(image_path, detections):\n",
        "    \"\"\"\n",
        "    Visualizes detection results using OpenCV.\n",
        "\n",
        "    Args:\n",
        "    - image_path (str): Path to the input image.\n",
        "    - detections (DataFrame): Detected objects with their bounding boxes and confidence scores.\n",
        "    \"\"\"\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    for _, row in detections.iterrows():\n",
        "        # Extract bounding box coordinates\n",
        "        x_min, y_min, x_max, y_max = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
        "        label = f\"{row['name']} ({row['confidence']:.2f})\"\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
        "        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    # Display the image\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"YOLOv5 Detection Results\")\n",
        "    plt.show()\n",
        "\n",
        "# Visualize bounding boxes\n",
        "visualize_results(image_path, detections)"
      ],
      "metadata": {
        "id": "HucLV4dhKkcC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}